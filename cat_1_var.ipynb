{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff770a12",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "1.1. [Load Data](#toc1_1_)    \n",
    "1.2. [Basic Summary Statistics](#toc1_2_)    \n",
    "1.3. [Data Visualization](#toc1_3_)    \n",
    "1.4. [Assumptions Check](#toc1_4_)    \n",
    "1.4.1. [Normality](#toc1_4_1_)    \n",
    "1.4.2. [Robustness](#toc1_4_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=true\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20971c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# force reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2e585",
   "metadata": {},
   "source": [
    "## 1.1. <a id='toc1_1_'></a>[Load Data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a859af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Opinion\n",
       "0     yes\n",
       "1     yes\n",
       "2     yes\n",
       "3     yes\n",
       "4      no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"data/data.xlsx\", sheet_name='cat_univar')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b09131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Opinion\n",
       "no         71\n",
       "yes        68\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bbc7df",
   "metadata": {},
   "source": [
    "## 1.2. <a id='toc1_2_'></a>[Basic Summary Statistics](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab7a08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbc95b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values.flatten()\n",
    "n = 50\n",
    "X = np.random.choice(['yes', 'no'], size=n, p=[22/50, 28/50])\n",
    "X = ['yes'] * 25 + ['no'] * 15 + ['idk'] * 5\n",
    "X= np.array(X, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dab6f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      45\n",
       "unique      3\n",
       "top       yes\n",
       "freq       25\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats = pd.Series(X).describe()\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935de986",
   "metadata": {},
   "source": [
    "## 1.3. <a id='toc1_3_'></a>[Data Visualization](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f2a79ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee0439052b84957816adda1955c3fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Stats:', options=('count', 'proportion', 'probability', 'percent')â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.stattools import medcouple\n",
    "\n",
    "\n",
    "def plot_univariate_cat(X, y_stats=\"proportion\"):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    # plot conts values using plt\n",
    "    sns.countplot(\n",
    "        x=X,\n",
    "        order=np.unique(X),\n",
    "        palette=\"pastel\",\n",
    "        hue=X,\n",
    "        edgecolor=\"black\",\n",
    "        stat=y_stats,\n",
    "        width=0.5,\n",
    "    )\n",
    "    # set labels with counts\n",
    "    counts = pd.Series(X).value_counts()\n",
    "    labels = [f\"{count} {label}\" for label, count in counts.to_dict().items()]\n",
    "    plt.xticks(ticks=np.arange(len(labels)), labels=labels)\n",
    "    plt.title(\"Categorical Variable Distribution\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "widgets.interact(\n",
    "    plot_univariate_cat,\n",
    "    X=widgets.fixed(X),\n",
    "    y_stats=widgets.Dropdown(\n",
    "        options=[\"count\", \"proportion\", \"probability\", \"percent\"], description=\"Stats:\"\n",
    "    ),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4cea8",
   "metadata": {},
   "source": [
    "## 1.4. <a id='toc1_4_'></a>[One Proportion Test](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c333148",
   "metadata": {},
   "source": [
    "#### 2 Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd2d58",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Utility to recommend which test to use for a 1-sample proportion:\n",
    "- Exact binomial test (`scipy.stats.binomtest`)\n",
    "- Normal approximation z-test (`statsmodels.stats.proportion.proportions_ztest`)\n",
    "\n",
    "Heuristics used:\n",
    "1. If n is small  -> prefer binomtest\n",
    "2. If expected counts (n * p0 or n * (1 - p0)) are small -> prefer binomtest\n",
    "3. If hypothesized proportion p0 is very close to 0 or 1 (skewed) -> prefer binomtest\n",
    "Otherwise -> z-test is fine.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9aa269a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successes observed: 25\n",
      "Number of categories: 3\n",
      "Total number of observations: 45\n",
      "Sample proportion: 0.556\n",
      "Hypothesized population proportion: 0.333\n"
     ]
    }
   ],
   "source": [
    "# get data parameters\n",
    "observed = np.unique_counts(X).counts # Observed frequencies for all categories\n",
    "count = observed.max()   # set dynamically Number of successes observed\n",
    "n_cat = len(observed)\n",
    "n = observed.sum()  # Total number of observations\n",
    "p =  count / n # sample proportion\n",
    "p0 = 1/n_cat # Hypothesized population proportion P0 = P\n",
    "\n",
    "print(f\"Number of successes observed: {count}\")\n",
    "print(f\"Number of categories: {n_cat}\")\n",
    "print(f\"Total number of observations: {n}\")\n",
    "print(f\"Sample proportion: {p:.3f}\")\n",
    "print(f\"Hypothesized population proportion: {p0:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f366f908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test is not appropriate: variable is not binary\n",
      "Use the chi-square test for more than 2 categories, followed by a post-hoc test\n"
     ]
    }
   ],
   "source": [
    "if n_cat == 2:\n",
    "    # Perform the exact binomial test\n",
    "    result = stats.binomtest(k=count, n=n, p=p0, alternative='two-sided')\n",
    "    print(f\"P-value: {result.pvalue:.4f}\")\n",
    "    print(f\"Test statistic (proportion estimate): {result.statistic:.4f}\")\n",
    "\n",
    "    # Access the confidence interval\n",
    "    ci = result.proportion_ci(confidence_level=0.95)\n",
    "    print(f\"95% Confidence Interval: [{ci.low:.2f}, {ci.high:.2f}]\")\n",
    "\n",
    "    # Interpretation:\n",
    "    alpha = 0.05\n",
    "    if result.pvalue < alpha:\n",
    "        print(f\"\\tReject H0: The true proportion is significantly different from {p0:.2f}\")\n",
    "    else:\n",
    "        print(f\"\\tFail to reject H0: No evidence that the true proportion differs from {p0:.2f}\")\n",
    "else:\n",
    "    print(\"The test is not appropriate: variable is not binary\")\n",
    "    print(\"Use the chi-square test for more than 2 categories, followed by a post-hoc test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4325b66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test is not appropriate: variable is not binary\n",
      "Use the chi-square test for more than 2 categories, followed by a post-hoc test\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "if n_cat == 2:\n",
    "    # Perform one-sample z-test for proportion\n",
    "    stat, p_value = proportions_ztest(count=count, nobs=n, value=p0, alternative='two-sided')\n",
    "\n",
    "    print(f\"Successes: {count}\")\n",
    "    print(f\"Total n: {n}\")\n",
    "    print(f\"Hypothesized proportion p0 : {p0:.4f}\")\n",
    "    print(f\"Z-statistic: {stat:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "    # Simple interpretation at alpha = 0.05\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(\"\\tReject H0: The true proportion is significantly different from p0\")\n",
    "    else:\n",
    "        print(\"\\tFail to reject H0: No evidence that the true proportion differs from p0\")\n",
    "else:\n",
    "    print(\"The test is not appropriate: variable is not binary\")\n",
    "    print(\"Use the chi-square test for more than 2 categories, followed by a post-hoc test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb248a",
   "metadata": {},
   "source": [
    "#### 3 or more Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1d1f38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed counts: [ 5 15 25]\n",
      "Expected counts: [15. 15. 15.]\n",
      "Chi-square statistic: 13.33\n",
      "p-value: 0.0013\n",
      "\tReject H0: The distribution is not uniform across the 3 categories.\n"
     ]
    }
   ],
   "source": [
    "# Observed frequencies for the 3 categories\n",
    "# observed = np.unique_counts(X).counts\n",
    "# n_cat = len(observed)\n",
    "# # Total number of observations\n",
    "# n = observed.sum()\n",
    "\n",
    "# Expected frequencies under H0: uniform distribution across 3 categories\n",
    "expected = np.array([n / n_cat] * n_cat)\n",
    "\n",
    "# Perform chi-square goodness-of-fit test\n",
    "chi2_stat, p_value = stats.chisquare(f_obs=observed, f_exp=expected)\n",
    "\n",
    "print(\"Observed counts:\", observed)\n",
    "print(\"Expected counts:\", expected)\n",
    "print(f\"Chi-square statistic: {chi2_stat:.2f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Optional: simple interpretation at alpha = 0.05\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"\\tReject H0: The distribution is not uniform across the {n_cat} categories.\")\n",
    "else:\n",
    "    print(\"Fail to reject H0: No evidence against a uniform distribution across the {n_cat} categories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da332f8",
   "metadata": {},
   "source": [
    "* **Post-Hoc Analysis**: Pairewise chi-square propotion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbb62d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________Need Post-Hoc Analysis___________\n",
      "Alpha: 0.05, Bonferroni-corrected alpha: 0.0167 (n_comparisons=3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group1</th>\n",
       "      <th>group2</th>\n",
       "      <th>Chi2</th>\n",
       "      <th>p-value</th>\n",
       "      <th>p-value_corrected</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.113846</td>\n",
       "      <td>0.341539</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>idk</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>idk</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.025347</td>\n",
       "      <td>0.076042</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group1 group2       Chi2   p-value  p-value_corrected  significant\n",
       "0    yes     no   2.500000  0.113846           0.341539        False\n",
       "1    yes    idk  13.333333  0.000261           0.000782         True\n",
       "2     no    idk   5.000000  0.025347           0.076042        False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chisquare\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"__________Need Post-Hoc Analysis___________\")\n",
    "    \n",
    "    # Get counts\n",
    "    counts = Counter(X)\n",
    "    alpha = 0.05\n",
    "    \n",
    "    # Bonferroni correction\n",
    "    n_comparisons = len(list(combinations(counts.keys(), 2)))\n",
    "    # Bonferroni correction to account for multiple comparisons (optional but recommended)\n",
    "    use_correction = True\n",
    "    alpha_corrected = alpha / n_comparisons\n",
    "    \n",
    "    # Pairwise chi-square tests using combinations\n",
    "    results = []\n",
    "    for cat1, cat2 in combinations(counts.keys(), 2):\n",
    "        obs = [counts[cat1], counts[cat2]]\n",
    "        chi2, pval = chisquare(obs)\n",
    "        results.append({\n",
    "\t\t\t'group1': cat1, \n",
    "\t\t\t'group2': cat2, \n",
    "\t\t\t'Chi2': chi2, \n",
    "\t\t\t'p-value': pval, \n",
    "\t\t\t'p-value_corrected': min(pval * n_comparisons, 1.0),\n",
    "\t\t\t'significant': pval < alpha_corrected if use_correction else pval < alpha\n",
    "\t\t})\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(f\"Alpha: {alpha}, Bonferroni-corrected alpha: {alpha_corrected:.4f} (n_comparisons={n_comparisons})\\n\")\n",
    "    display(df_results)\n",
    "else:\n",
    "    print(\"No need to do Post-Hoc Analysis because p-value is not significant\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
